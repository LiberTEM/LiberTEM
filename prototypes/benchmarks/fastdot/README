Benchmark for different tilings and loop orders for mask application

The basic innermost operation for simple pixelated STEM is the dot product
(element-wise matrix multiplication and summation of the results) of detector frame
with a mask. Memory bandwidth is the bottleneck for this operation - so the
faster we can get our data to the CPU, the better. 

In most cases, this mask is larger than the L2 cache.
For our application, the mask stays constant for many frames. We can
exploit this by dividing our data into tiles and changing the loop order to
keep a tile of the mask in the L2 cache for a number of frames. That should
free up more bandwidth for loading frame data (in theory it should have
about 2x the bandwidth available).

This benchmark allows us to test different tile sizes, different frame sizes
and how many frame tiles to process while keeping the mask constant. It also
validates that performance drops off significantly if we use a tile size that is
too large, or if we don't exploit the constant mask at all (see bench4 and bench6).
