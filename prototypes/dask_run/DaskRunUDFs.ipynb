{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bfdbc51",
   "metadata": {},
   "source": [
    "# DaskDataSet Example\n",
    "\n",
    "Creates a ~2.5 GB raw dataset, loads it as a chunked Dask array and then runs sig and nav sum UDFs on it.\n",
    "\n",
    "The only new code in LiberTEM is the Dask array wrapper, it wasn't necessary to modify the UDFRunner or other endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb016e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from time import perf_counter\n",
    "from contextlib import contextmanager\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import distributed\n",
    "import dask\n",
    "import dask.array as da\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20caa1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import libertem.api as lt\n",
    "from libertem.executor.dask import DaskJobExecutor\n",
    "from libertem.io.dataset.dask import DaskDataSet\n",
    "from libertem.udf.sum import SumUDF\n",
    "from libertem.udf.sumsigudf import SumSigUDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f961af6e",
   "metadata": {},
   "source": [
    "### Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e33cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_raw_ds(fpath, dtype, sig_shape, nav_shape, div=0):\n",
    "    assert sig_shape[0] == sig_shape[1]\n",
    "    dim = sig_shape[0]\n",
    "    ramp = np.linspace(0, 1., num=dim, endpoint=True, dtype=dtype)\n",
    "    base_array = ramp[:, np.newaxis] * ramp[np.newaxis, :]\n",
    "    if div > 0:\n",
    "        stripe = dim // div\n",
    "        linear_mask = np.zeros((dim,), dtype=bool)\n",
    "        for s in range(stripe//2, dim, 2*stripe):\n",
    "            linear_mask[s:s+stripe] = True\n",
    "        base_array[linear_mask,:] = 0\n",
    "        base_array[:, linear_mask] = 0\n",
    "    with pathlib.Path(fpath).open('wb') as fp:\n",
    "        for idx in range(np.prod(nav_shape)):\n",
    "            fp.write((base_array * idx).data)  \n",
    "            \n",
    "@contextmanager\n",
    "def timer(msg=None):\n",
    "    start = perf_counter()\n",
    "    yield\n",
    "    if msg is None:   \n",
    "        print(f'{perf_counter()-start:.3f} s')\n",
    "    else:\n",
    "        print(f'{msg} - {perf_counter()-start:.3f} s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765219a0",
   "metadata": {},
   "source": [
    "### Setup Dask/Distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600bbcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('Create Dask Scheduler'):\n",
    "    client = distributed.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d175f3eb",
   "metadata": {},
   "source": [
    "### Parameters and make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2576b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path('./ds.raw').absolute()\n",
    "nav_shape = (70,128)\n",
    "sig_shape = (256,256)\n",
    "shape = nav_shape + sig_shape\n",
    "dtype = np.float32\n",
    "blocksize = 8\n",
    "if not path.is_file():\n",
    "    make_raw_ds(path, np.float32, sig_shape, nav_shape, div=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2df01a",
   "metadata": {},
   "source": [
    "### da.array creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7879fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmap_load_chunk(filename, shape, dtype, offset, sl):\n",
    "    data = np.memmap(filename, mode='r', shape=shape, dtype=dtype, offset=offset)\n",
    "    return data[sl]\n",
    "\n",
    "\n",
    "def load_chunk(filename, shape, dtype, offset, sl):\n",
    "    #offset is not supported with this nb read function except for an integer number of items\n",
    "    dtype_bytes = np.dtype(dtype).itemsize\n",
    "    macroframe_itemsize = math.prod(shape[1:])\n",
    "    start_item = sl.start *  macroframe_itemsize\n",
    "    end_item = sl.stop * macroframe_itemsize\n",
    "    np_shape = (sl.stop - sl.start,) + shape[1:]\n",
    "    with filename.open('rb') as fp:\n",
    "        return np.fromfile(fp, offset=start_item * dtype_bytes, dtype=dtype, count=end_item - start_item).reshape(np_shape)\n",
    "\n",
    "\n",
    "def mmap_dask_array(filename, shape, dtype, offset=0, blocksize=8):\n",
    "    if False or os.name == 'nt':\n",
    "        load = dask.delayed(load_chunk)\n",
    "    else:\n",
    "        load = dask.delayed(mmap_load_chunk)\n",
    "    chunks = []\n",
    "    for index in range(0, shape[0], blocksize):\n",
    "        # Truncate the last chunk if necessary\n",
    "        chunk_size = min(blocksize, shape[0] - index)\n",
    "        chunk = dask.array.from_delayed(\n",
    "            load(\n",
    "                filename,\n",
    "                shape=shape,\n",
    "                dtype=dtype,\n",
    "                offset=offset,\n",
    "                sl=slice(index, index + chunk_size)\n",
    "            ),\n",
    "            shape=(chunk_size, ) + shape[1:],\n",
    "            dtype=dtype\n",
    "        )\n",
    "        chunks.append(chunk)\n",
    "    return chunks, da.concatenate(chunks, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffbb407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chunks, d_arr = mmap_dask_array(\n",
    "    filename=path,\n",
    "    shape=shape,\n",
    "    dtype=dtype,\n",
    "    blocksize=blocksize\n",
    ")\n",
    "d_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c308d35",
   "metadata": {},
   "source": [
    "### Load LiberTEM context and the DaskDataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ced39e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "executor = DaskJobExecutor(client)\n",
    "ctx = lt.Context(executor=executor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988d3ab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds = DaskDataSet(d_arr, nav_shape=nav_shape, sig_shape=sig_shape)    \n",
    "ds.initialize(executor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b32ec",
   "metadata": {},
   "source": [
    "#### Try to warm up the filecache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65450af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with path.open('rb') as fp:\n",
    "    array = np.fromfile(fp, dtype=dtype).reshape(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c4219f",
   "metadata": {},
   "source": [
    "#### Run UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83197771",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_udf = SumUDF()\n",
    "sigsum_udf = SumSigUDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8946052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('Run UDFs'):\n",
    "    res = ctx.run_udf(ds, [sum_udf, sigsum_udf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2072000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 6))\n",
    "axs[0].imshow(res[0]['intensity'].data);\n",
    "axs[0].set_title('Sum over nav axes');\n",
    "axs[1].imshow(res[1]['intensity'].data);\n",
    "axs[1].set_title('Sum over sig axes');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255d3481",
   "metadata": {},
   "source": [
    "### Numpy-only, whole file read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2a6c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('Numpy single read'):\n",
    "    with path.open('rb') as fp:\n",
    "        array = np.fromfile(fp, dtype=dtype).reshape(shape)\n",
    "    xx = array.sum(axis=(0, 1))\n",
    "    yy = array.sum(axis=(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e933ce",
   "metadata": {},
   "source": [
    "### Numpy-only, partitioned reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2362b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('Numpy partitioned read'):\n",
    "    for index in range(0, shape[0], blocksize):\n",
    "        chunk_size = min(blocksize, shape[0] - index)\n",
    "        array = load_chunk(\n",
    "            path,\n",
    "            shape=shape,\n",
    "            dtype=dtype,\n",
    "            offset=0,\n",
    "            sl=slice(index, index + chunk_size))\n",
    "        xx = array.sum(axis=(0, 1))\n",
    "        yy = array.sum(axis=(2, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
